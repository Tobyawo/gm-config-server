# /etc/logstash/conf.d/pipeline.conf

input { beats { port => 5044 } }


#If you only want logs with specific tags, don’t drop everything by default.

filter {
  if [tags] and [tags] !~ /gm-access-service|gm-user-service/ {
    drop { }
  }
  mutate { add_field => { "log_source" => "%{[tags]}" } }
}


#filter {
#  # Only drop when tags exist AND don't match
#  if [tags] {
#    if !( [tags] =~ /gm-access-service|gm-user-service/ ) {
#      drop { }
#    } else {
#      mutate { add_field => { "log_source" => "%{tags}" } }
#    }
#  }
#  # If no [tags] field at all, keep the event (or drop it—your call)
#}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
}


#If still empty, do a quick end-to-end smoke test by injecting one doc directly (just to prove Grafana can work once data exists):
#
#curl -s -X POST "http://localhost:9200/logs-$(date +%Y.%m.%d)/_doc" \
#  -H 'Content-Type: application/json' \
#  -d '{"@timestamp":"'"$(date -u +%Y-%m-%dT%H:%M:%SZ)"'","message":"hello from test"}'
